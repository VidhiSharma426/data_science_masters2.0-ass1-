{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0976d8fd",
   "metadata": {},
   "source": [
    "### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b2961",
   "metadata": {},
   "source": [
    "Min-Max scaling is a data preprocessing technique used to transform numerical features to a specific range, typically between 0 and 1. The transformation is done by subtracting the minimum value of the feature and then dividing by the range (the difference between the maximum and minimum values). The formula is as follows:\n",
    "\n",
    "Scaled Value\n",
    "    =\n",
    "Original Value\n",
    "−\n",
    "Min Value\n",
    "Max Value\n",
    "−\n",
    "Min Value\n",
    "Scaled Value= \n",
    "Max Value−Min Value\n",
    "Original Value−Min Value\n",
    "​\n",
    " \n",
    "\n",
    "This scaling method is useful when the features have different ranges, and it ensures that all features contribute equally to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75a2c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[ 1.  5.]\n",
      " [10. 15.]\n",
      " [20. 25.]]\n",
      "\n",
      "Scaled Data:\n",
      "[[0.         0.        ]\n",
      " [0.47368421 0.5       ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Original data\n",
    "data = np.array([[1.0, 5.0],\n",
    "                 [10.0, 15.0],\n",
    "                 [20.0, 25.0]])\n",
    "\n",
    "# Apply Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nScaled Data:\")\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f432aa",
   "metadata": {},
   "source": [
    "### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140b2ec",
   "metadata": {},
   "source": [
    "The Unit Vector technique in feature scaling involves scaling each feature by dividing it by its magnitude (Euclidean norm). The formula for unit vector scaling is:\n",
    "\n",
    "Unit Vector\n",
    "    =\n",
    "Original Value\n",
    "∥\n",
    "Original Value\n",
    "∥\n",
    "Unit Vector= \n",
    "∥Original Value∥\n",
    "Original Value\n",
    "​\n",
    " \n",
    "\n",
    "This technique ensures that the scaled values lie on the unit circle, and the direction of the vector remains unchanged.\n",
    "\n",
    "Difference from Min-Max Scaling:\n",
    "\n",
    "Min-Max scaling scales the values based on their range, bringing them within a specific range (e.g., 0 to 1).\n",
    "Unit vector scaling focuses on the direction of the vector, ensuring that all vectors have the same direction but possibly different magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfa1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[ 1.  5.]\n",
      " [10. 15.]\n",
      " [20. 25.]]\n",
      "\n",
      "Unit Vector Scaled Data:\n",
      "[[0.19611614 0.98058068]\n",
      " [0.5547002  0.83205029]\n",
      " [0.62469505 0.78086881]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Original data\n",
    "data = np.array([[1.0, 5.0],\n",
    "                 [10.0, 15.0],\n",
    "                 [20.0, 25.0]])\n",
    "\n",
    "# Apply Unit Vector scaling\n",
    "scaler = Normalizer()\n",
    "unit_vector_scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nUnit Vector Scaled Data:\")\n",
    "print(unit_vector_scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b644e1",
   "metadata": {},
   "source": [
    "\n",
    "### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c9bce",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space while retaining as much variance as possible. It achieves this by identifying the principal components, which are linear combinations of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a340da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "Transformed Data (After PCA):\n",
      "[[ 5.19615242  0.        ]\n",
      " [-0.          0.        ]\n",
      " [-5.19615242  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Original data\n",
    "data = np.array([[1.0, 2.0, 3.0],\n",
    "                 [4.0, 5.0, 6.0],\n",
    "                 [7.0, 8.0, 9.0]])\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nTransformed Data (After PCA):\")\n",
    "print(transformed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce26b1",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe7caa",
   "metadata": {},
   "source": [
    "Relationship with Feature Extraction:\n",
    "\n",
    "PCA is a technique for both dimensionality reduction and feature extraction.\n",
    "In the context of feature extraction, PCA identifies a new set of features (principal components) that capture the maximum variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56244371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "Transformed Data (Principal Components):\n",
      "[[ 5.19615242  0.        ]\n",
      " [-0.          0.        ]\n",
      " [-5.19615242  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Assume 'data' is the original dataset\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nTransformed Data (Principal Components):\")\n",
    "print(transformed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad82ddf",
   "metadata": {},
   "source": [
    "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131500b",
   "metadata": {},
   "source": [
    "In the context of building a recommendation system for a food delivery service, you can use Min-Max scaling to preprocess the data, ensuring that features like price, rating, and delivery time are on a similar scale. This allows the model to consider each feature equally when making recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598f2e1",
   "metadata": {},
   "source": [
    "### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d4da33e",
   "metadata": {},
   "source": [
    "For predicting stock prices with a dataset containing numerous features, PCA can be used to reduce the dimensionality of the dataset. By retaining the principal components that capture the most variance, PCA helps in simplifying the model and improving computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94086f58",
   "metadata": {},
   "source": [
    "### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fce4c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Values:\n",
      "[[ 1]\n",
      " [ 5]\n",
      " [10]\n",
      " [15]\n",
      " [20]]\n",
      "\n",
      "Scaled Values (Min-Max Scaling -1 to 1):\n",
      "[[-1.        ]\n",
      " [-0.57894737]\n",
      " [-0.05263158]\n",
      " [ 0.47368421]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Original dataset\n",
    "values = np.array([1, 5, 10, 15, 20]).reshape(-1, 1)\n",
    "\n",
    "# Apply Min-Max scaling to transform values to a range of -1 to 1\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "print(\"Original Values:\")\n",
    "print(values)\n",
    "print(\"\\nScaled Values (Min-Max Scaling -1 to 1):\")\n",
    "print(scaled_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ef5dd2",
   "metadata": {},
   "source": [
    "### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b9ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features:\n",
      "[[170  65  30   1 120]\n",
      " [160  55  28   0 110]\n",
      " [180  75  35   1 130]]\n",
      "\n",
      "Principal Components after PCA:\n",
      "[[-1.89049746e-01  1.03700111e+00  8.29611047e-16]\n",
      " [-1.75831427e+01 -5.26818033e-01  8.29611047e-16]\n",
      " [ 1.77721924e+01 -5.10183078e-01  8.29611047e-16]]\n",
      "\n",
      "Explained Variance Ratio:\n",
      "[9.97425752e-01 2.57424785e-03 3.29483532e-33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Original dataset\n",
    "features = np.array([[170, 65, 30, 1, 120],\n",
    "                     [160, 55, 28, 0, 110],\n",
    "                     [180, 75, 35, 1, 130]])\n",
    "\n",
    "# Apply PCA for feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "principal_components = pca.fit_transform(features)\n",
    "\n",
    "print(\"Original Features:\")\n",
    "print(features)\n",
    "print(\"\\nPrincipal Components after PCA:\")\n",
    "print(principal_components)\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4fe1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

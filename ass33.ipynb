{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb22bb5",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bab1f3",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across multiple groups. To ensure the validity of ANOVA results, certain assumptions must be met. Here are the key assumptions required for the proper application of ANOVA:\n",
    "\n",
    "1. **Normality**: The data within each group should follow a roughly normal distribution. This assumption is more critical when the sample sizes are small.\n",
    "\n",
    "   *Violation Example*: If the data is strongly skewed or does not follow a normal distribution, ANOVA results may be less reliable. Transforming the data or using non-parametric alternatives may be considered in such cases.\n",
    "\n",
    "2. **Homogeneity of Variances (Homoscedasticity)**: The variances of the different groups should be approximately equal. This means that the spread or dispersion of the data points should be consistent across groups.\n",
    "\n",
    "   *Violation Example*: If the variances are not equal, ANOVA may become less robust. Welch's ANOVA or a transformation of the data might be considered if variances are significantly different.\n",
    "\n",
    "3. **Independence**: Observations within each group must be independent of each other. The values in one group should not be related to the values in another group.\n",
    "\n",
    "   *Violation Example*: If there is dependence between observations (e.g., repeated measures or paired observations), standard ANOVA may not be appropriate. Repeated measures ANOVA or mixed-effects models might be more suitable.\n",
    "\n",
    "4. **Random Sampling**: The data should be collected through a random sampling process to ensure generalizability of results to the population.\n",
    "\n",
    "   *Violation Example*: If the sampling is not random, it may lead to biased estimates, affecting the generalizability of the ANOVA results.\n",
    "\n",
    "5. **Interval or Ratio Data**: ANOVA assumes that the dependent variable is measured on an interval or ratio scale. This is necessary to perform meaningful calculations of means and variances.\n",
    "\n",
    "   *Violation Example*: If the data is ordinal or nominal, ANOVA might not be the most appropriate test. Non-parametric alternatives like the Kruskal-Wallis test may be considered.\n",
    "\n",
    "6. **No Significant Outliers**: Outliers can unduly influence the results of ANOVA, especially when sample sizes are small. Checking for and addressing outliers is essential.\n",
    "\n",
    "   *Violation Example*: If significant outliers exist, they may skew results, and it might be necessary to either address the outliers or use non-parametric tests that are less sensitive to extreme values.\n",
    "\n",
    "When these assumptions are violated, it is important to consider alternative analysis methods or transformations of the data to ensure the validity of statistical tests. Additionally, if the sample size is large, ANOVA can be robust to violations of normality and homogeneity of variances. Always be cautious and use additional diagnostic tools to assess the robustness of your results when assumptions are not fully met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074cb3a2",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d111b",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) comes in several types, each designed for specific situations and research designs. The three main types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA (One-Factor ANOVA)**:\n",
    "   - **Usage**: Used when comparing means across more than two independent groups (levels of a single factor).\n",
    "   - **Example**: Comparing the average scores of students in three different teaching methods (groups A, B, and C).\n",
    "\n",
    "   In a one-way ANOVA, you are testing the null hypothesis that there are no significant differences in the means of the groups. If the null hypothesis is rejected, it suggests that at least one group differs significantly from the others.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - **Usage**: Used when there are two independent variables (factors) influencing the dependent variable.\n",
    "   - **Example**: Investigating the effects of two different factors, such as the impact of a new drug (factor A) and the gender of patients (factor B) on blood pressure.\n",
    "\n",
    "   Two-way ANOVA allows you to examine the main effects of each factor as well as their interaction effect. The interaction effect tests whether the effect of one factor depends on the level of the other factor.\n",
    "\n",
    "3. **Repeated Measures ANOVA (Within-Subjects ANOVA)**:\n",
    "   - **Usage**: Used when the same subjects are used for each treatment (repeated measurements on the same subjects).\n",
    "   - **Example**: Assessing the effectiveness of a weight loss program by measuring participants' weights before and after treatment.\n",
    "\n",
    "   Repeated Measures ANOVA is appropriate when you want to compare means of related groups or when each subject is exposed to more than one condition. This type of ANOVA is beneficial when dealing with data collected across time, conditions, or experimental manipulations on the same set of subjects.\n",
    "\n",
    "In summary:\n",
    "- **One-Way ANOVA**: Compares means across multiple independent groups (levels of one factor).\n",
    "- **Two-Way ANOVA**: Examines the effects of two independent variables (factors) on the dependent variable and their interaction.\n",
    "- **Repeated Measures ANOVA**: Used when there are repeated measurements on the same subjects.\n",
    "\n",
    "Choosing the appropriate type of ANOVA depends on the research design, the number of factors, and the relationships between variables in your study. It's essential to consider the experimental or observational setup to determine the most suitable ANOVA design for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe03539",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b818df",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variability in the data into different components or sources. Understanding this concept is crucial for interpreting ANOVA results and gaining insights into the relative contributions of various factors to the overall variability observed in the data. The partitioning of variance is typically illustrated in the ANOVA table.\n",
    "\n",
    "The ANOVA table is structured as follows:\n",
    "\n",
    "```\n",
    "Source of Variation | Sum of Squares (SS) | Degrees of Freedom (df) | Mean Square (MS) | F-ratio\n",
    "-------------------------------------------------------------------------------\n",
    "Between Groups      | SS_between            | df_between             | MS_between         | F = MS_between / MS_within\n",
    "Within (or Residual) | SS_within             | df_within              | MS_within          |\n",
    "Total                | SS_total              | df_total               |\n",
    "```\n",
    "\n",
    "Here's a breakdown of each component:\n",
    "\n",
    "1. **Between Groups Variability (SS_between):**\n",
    "   - Represents the variation in the dependent variable attributable to differences between the group means.\n",
    "   - It compares the variability among group means to the variability within groups.\n",
    "   - A larger SS_between suggests that the means of the groups are more different.\n",
    "\n",
    "2. **Within (or Residual) Variability (SS_within):**\n",
    "   - Represents the variation in the dependent variable that is not explained by the differences between group means.\n",
    "   - It reflects the random variability or individual differences within each group.\n",
    "   - A smaller SS_within indicates less variability within groups.\n",
    "\n",
    "3. **Total Variability (SS_total):**\n",
    "   - Represents the overall variability in the dependent variable.\n",
    "   - It is the sum of the between-groups and within-groups variability.\n",
    "   - SS_total = SS_between + SS_within\n",
    "\n",
    "4. **Degrees of Freedom (df):**\n",
    "   - The degrees of freedom associated with each source of variation.\n",
    "   - df_between is the degrees of freedom for the between-groups variability.\n",
    "   - df_within is the degrees of freedom for the within-groups variability.\n",
    "   - df_total is the total degrees of freedom, equal to the sum of df_between and df_within.\n",
    "\n",
    "5. **Mean Squares (MS):**\n",
    "   - Calculated by dividing the sum of squares by the degrees of freedom.\n",
    "   - MS_between = SS_between / df_between\n",
    "   - MS_within = SS_within / df_within\n",
    "\n",
    "6. **F-ratio:**\n",
    "   - Represents the ratio of the mean square between groups to the mean square within groups.\n",
    "   - The F-ratio is used to test whether the differences between group means are statistically significant.\n",
    "   - A larger F-ratio suggests a greater likelihood that the group means are different.\n",
    "\n",
    "Understanding the partitioning of variance is essential because it allows researchers to evaluate the relative importance of different factors in explaining the variability in the data. It helps in assessing the significance of group differences, determining the effectiveness of experimental manipulations, and identifying potential sources of variation. Additionally, interpreting the F-ratio and associated p-value allows researchers to make informed decisions about the presence or absence of statistically significant differences between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ae3f0",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1c23234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 543.6\n",
      "Explained Sum of Squares (SSE): 491.2\n",
      "Residual Sum of Squares (SSR): 52.400000000000034\n",
      "19.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "group1 = np.array([10, 12, 15, 14, 13])\n",
    "group2 = np.array([18, 20, 17, 22, 19])\n",
    "group3 = np.array([25, 28, 30, 24, 27])\n",
    "\n",
    "# Combine the data from all groups\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate overall mean (grand mean)\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group_means = [np.mean(group) for group in [group1, group2, group3]]\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "sse = np.sum([len(group) * (group_mean - overall_mean)**2 for group, group_mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Sum of Squares (SST): {sst}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {sse}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {ssr}\")\n",
    "# print(overall_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f745ad4",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1ec0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: 790.511299435029\n",
      "Main Effect of Factor 2: 133.54591481964448\n",
      "Interaction Effect: 13.434854411125718\n",
      "790.511299435029\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "data = {\n",
    "    'Factor1': [10, 15, 20, 25, 30, 12, 18, 24, 14, 22],\n",
    "    'Factor2': ['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B'],\n",
    "    'DependentVar': [32, 45, 50, 60, 65, 28, 35, 40, 42, 55]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'DependentVar ~ Factor1 + Factor2 + Factor1:Factor2'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_factor1 = anova_table['sum_sq']['Factor1'] / anova_table['df']['Factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['Factor2'] / anova_table['df']['Factor2']\n",
    "interaction_effect = anova_table['sum_sq']['Factor1:Factor2'] / anova_table['df']['Factor1:Factor2']\n",
    "\n",
    "# Print the results\n",
    "print(f\"Main Effect of Factor 1: {main_effect_factor1}\")\n",
    "print(f\"Main Effect of Factor 2: {main_effect_factor2}\")\n",
    "print(f\"Interaction Effect: {interaction_effect}\")\n",
    "print(anova_table['sum_sq']['Factor1'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f9688",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f446a7",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are statistically significant differences in the means of the groups. The associated p-value indicates the probability of observing such differences by chance alone. Here's how you can interpret the results:\n",
    "\n",
    "1. **Null Hypothesis (H₀):** The null hypothesis in ANOVA is that there are no significant differences in the means of the groups.\n",
    "\n",
    "2. **Alternative Hypothesis (H₁):** The alternative hypothesis is that at least one group mean is different from the others.\n",
    "\n",
    "Given the F-statistic of 5.23 and a p-value of 0.02:\n",
    "\n",
    "- **F-Statistic (5.23):**\n",
    "  - It represents the ratio of the variance between groups to the variance within groups. A larger F-statistic suggests greater differences between group means relative to within-group variability.\n",
    "\n",
    "- **p-value (0.02):**\n",
    "  - The p-value is the probability of obtaining an F-statistic as extreme as the one observed, assuming the null hypothesis is true. A low p-value (typically below the significance level, e.g., 0.05) indicates evidence against the null hypothesis.\n",
    "\n",
    "**Interpretation:**\n",
    "- Since the p-value (0.02) is less than the significance level (e.g., 0.05), you would reject the null hypothesis.\n",
    "\n",
    "**Conclusion:**\n",
    "- There is sufficient evidence to suggest that at least one group mean is different from the others.\n",
    "\n",
    "In practical terms, you can conclude that there are significant differences in the means of the groups. However, the ANOVA itself does not tell you which specific group(s) differ from each other. Post-hoc tests (e.g., Tukey's HSD, Bonferroni) or pairwise comparisons would be conducted to identify the specific groups that differ.\n",
    "\n",
    "Keep in mind that statistical significance does not necessarily imply practical significance, and the effect size should also be considered when interpreting the meaningfulness of the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6966062",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e6ec7",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important aspect of data analysis. The presence of missing data can impact the validity and reliability of the results. Here are common methods to handle missing data in the context of repeated measures ANOVA, along with potential consequences:\n",
    "\n",
    "### Methods for Handling Missing Data:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion):**\n",
    "   - **Method:** Exclude participants with missing data from the analysis.\n",
    "   - **Consequences:**\n",
    "     - Reduces the sample size.\n",
    "     - Can introduce bias if the missing data is not completely at random (MCAR).\n",
    "\n",
    "2. **Pairwise Deletion (Available Case Analysis):**\n",
    "   - **Method:** Include all available data for each comparison, handling missing values separately for each pair of variables.\n",
    "   - **Consequences:**\n",
    "     - Retains more data compared to listwise deletion.\n",
    "     - Estimates may be based on different subsets of the sample.\n",
    "\n",
    "3. **Imputation:**\n",
    "   - **Method:** Estimate missing values based on observed data. Common imputation methods include mean imputation, median imputation, regression imputation, or multiple imputation.\n",
    "   - **Consequences:**\n",
    "     - Imputation introduces additional uncertainty.\n",
    "     - The choice of imputation method can affect results.\n",
    "     - Assumes that the missing data mechanism is ignorable.\n",
    "\n",
    "### Potential Consequences of Handling Missing Data:\n",
    "\n",
    "1. **Reduced Statistical Power:**\n",
    "   - Handling missing data may reduce the effective sample size, leading to decreased statistical power.\n",
    "\n",
    "2. **Bias:**\n",
    "   - If the missing data is not completely at random (MCAR), excluding cases (complete case analysis) may introduce bias into the estimates.\n",
    "\n",
    "3. **Imprecise Estimates:**\n",
    "   - Imputation methods introduce additional uncertainty, and the precision of estimates may be affected.\n",
    "\n",
    "4. **Invalid Assumptions:**\n",
    "   - Imputation methods assume certain characteristics of the missing data mechanism. Violating these assumptions may lead to biased results.\n",
    "\n",
    "5. **Misinterpretation of Results:**\n",
    "   - Different methods of handling missing data can lead to different results, potentially leading to different interpretations of study findings.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Understand the Missing Data Mechanism:**\n",
    "   - Investigate whether missing data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "\n",
    "2. **Consider Multiple Imputation:**\n",
    "   - Multiple imputation involves creating multiple datasets with imputed values and averaging the results. It provides a more robust approach to handling missing data.\n",
    "\n",
    "3. **Sensitivity Analysis:**\n",
    "   - Conduct sensitivity analyses using different methods for handling missing data to assess the robustness of the results.\n",
    "\n",
    "4. **Transparent Reporting:**\n",
    "   - Clearly report how missing data was handled, and discuss the potential impact on results and interpretations.\n",
    "\n",
    "5. **Consult Statistical Experts:**\n",
    "   - If in doubt, consult with statisticians or data analysts who can provide guidance on the appropriate handling of missing data for your specific study design.\n",
    "\n",
    "In summary, handling missing data in repeated measures ANOVA requires careful consideration of the missing data mechanism, potential biases, and the choice of imputation method. Transparent reporting and sensitivity analyses can help ensure the robustness of study findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a438f0",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a58a8",
   "metadata": {},
   "source": [
    "Post-hoc tests are conducted after an analysis of variance (ANOVA) to determine which specific groups differ from each other when the overall ANOVA indicates a significant difference. Since ANOVA alone does not identify the specific groups with significant differences, post-hoc tests are applied for pairwise comparisons. Here are some common post-hoc tests and situations where each might be appropriate:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD):**\n",
    "   - **When to Use:**\n",
    "     - Used when you have more than two groups and want to compare all possible pairs.\n",
    "   - **Example:**\n",
    "     - In a study comparing the effectiveness of three different teaching methods, Tukey's HSD can be used to identify which pairs of teaching methods have significantly different mean scores.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **When to Use:**\n",
    "     - Useful when conducting multiple pairwise comparisons to control the familywise error rate.\n",
    "   - **Example:**\n",
    "     - In a clinical trial with four different treatment groups, Bonferroni correction can be applied to compare each treatment group with every other group while controlling for the increased risk of Type I error.\n",
    "\n",
    "3. **Holm's Method:**\n",
    "   - **When to Use:**\n",
    "     - Similar to Bonferroni, but potentially more powerful.\n",
    "   - **Example:**\n",
    "     - In a marketing study comparing the sales performance of five different product strategies, Holm's method can be employed to identify pairs of strategies with significantly different effects.\n",
    "\n",
    "4. **Sidak Correction:**\n",
    "   - **When to Use:**\n",
    "     - Controls the experimentwise error rate.\n",
    "   - **Example:**\n",
    "     - In a psychology experiment with multiple conditions, Sidak correction can be applied to make pairwise comparisons between conditions while managing the overall Type I error rate.\n",
    "\n",
    "5. **Dunnett's Test:**\n",
    "   - **When to Use:**\n",
    "     - Used when you have one control group and want to compare it with multiple treatment groups.\n",
    "   - **Example:**\n",
    "     - In a pharmaceutical study comparing the efficacy of a new drug with a placebo (control) and two other existing drugs, Dunnett's test can be applied to compare the new drug with the control and other drugs.\n",
    "\n",
    "6. **Scheffé's Test:**\n",
    "   - **When to Use:**\n",
    "     - Useful when sample sizes are unequal and groups have different variances.\n",
    "   - **Example:**\n",
    "     - In an educational study where class sizes vary, and there are multiple groups, Scheffé's test can be employed to perform pairwise comparisons while accounting for unequal variances.\n",
    "\n",
    "### Example Situation Requiring a Post-Hoc Test:\n",
    "\n",
    "Imagine a study comparing the academic performance of students exposed to three different teaching methods: Traditional Lectures, Problem-Based Learning, and Online Modules. After conducting a one-way ANOVA, if the ANOVA test indicates a significant overall difference in academic performance among the three teaching methods, a post-hoc test like Tukey's HSD could be applied to identify which specific pairs of teaching methods have significantly different mean scores. This helps in understanding the nuances of the observed differences and making more precise comparisons between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa5084",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2044ff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 7.467923640553487\n",
      "P-value: 0.0008149177088645907\n",
      "The one-way ANOVA is statistically significant.\n",
      "There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "diet_A = np.random.normal(loc=5, scale=2, size=50)  # Example data for diet A\n",
    "diet_B = np.random.normal(loc=4.5, scale=1.8, size=50)  # Example data for diet B\n",
    "diet_C = np.random.normal(loc=6, scale=2.5, size=50)  # Example data for diet C\n",
    "\n",
    "# Combine the data from all diets\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create labels for each diet group\n",
    "labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is not enough evidence to conclude significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c5ff8",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcf91f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         sum_sq    df         F    PR(>F)\n",
      "Software               2.514772   2.0  0.344485  0.709581\n",
      "Experience             0.479063   1.0  0.131248  0.718051\n",
      "Software:Experience    1.592393   2.0  0.218133  0.804472\n",
      "Residual             306.603758  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Generate example data\n",
    "software = np.repeat(['Program A', 'Program B', 'Program C'], 30)\n",
    "experience = np.tile(['Novice', 'Experienced'], 45)\n",
    "time_taken = np.random.normal(loc=10, scale=2, size=90)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Software': software, 'Experience': experience, 'TimeTaken': time_taken})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'TimeTaken ~ Software + Experience + Software:Experience'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29201cb",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4432e6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.754695943505282\n",
      "P-value: 3.819135262679469e-06\n",
      "The two-sample t-test is statistically significant.\n",
      "There are significant differences in test scores between the control and experimental groups.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   6.2615 0.001 3.6645 8.8585   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)  # Example data for the control group\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)  # Example data for the experimental group\n",
    "\n",
    "# Conduct a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Check if the results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"The two-sample t-test is statistically significant.\")\n",
    "    print(\"There are significant differences in test scores between the control and experimental groups.\")\n",
    "\n",
    "    # Perform post-hoc test (e.g., Tukey's HSD for two groups)\n",
    "    posthoc_result = mc.pairwise_tukeyhsd(np.concatenate([control_group, experimental_group]),\n",
    "                                           np.concatenate([['Control'] * 100, ['Experimental'] * 100]))\n",
    "\n",
    "    # Print the results of the post-hoc test\n",
    "    print(posthoc_result)\n",
    "else:\n",
    "    print(\"The two-sample t-test is not statistically significant.\")\n",
    "    print(\"There is not enough evidence to conclude significant differences in test scores between the control and experimental groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc4a92",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1629bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 23.805005398560485\n",
      "P-value: 5.678352754901736e-09\n",
      "The one-way ANOVA is statistically significant.\n",
      "There are significant differences in daily sales between the three stores.\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper   reject\n",
      "-----------------------------------------------------\n",
      "     A      B 102.1376  0.001 66.6479 137.6273   True\n",
      "     A      C  60.3093  0.001 24.8196   95.799   True\n",
      "     B      C -41.8283 0.0167 -77.318  -6.3386   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Sample data (replace with your own data)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sales_store_A = np.random.normal(loc=1000, scale=50, size=30)  # Example data for Store A\n",
    "sales_store_B = np.random.normal(loc=1100, scale=60, size=30)  # Example data for Store B\n",
    "sales_store_C = np.random.normal(loc=1050, scale=70, size=30)  # Example data for Store C\n",
    "\n",
    "# Combine the data from all stores\n",
    "all_sales_data = np.concatenate([sales_store_A, sales_store_B, sales_store_C])\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "df = pd.DataFrame({\n",
    "    'Sales': all_sales_data,\n",
    "    'Store': np.repeat(['A', 'B', 'C'], 30)\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "anova_result = stats.f_oneway(sales_store_A, sales_store_B, sales_store_C)\n",
    "\n",
    "# Print the results of the ANOVA\n",
    "print(f\"F-statistic: {anova_result.statistic}\")\n",
    "print(f\"P-value: {anova_result.pvalue}\")\n",
    "\n",
    "# Check if the results are significant\n",
    "if anova_result.pvalue < 0.05:\n",
    "    print(\"The one-way ANOVA is statistically significant.\")\n",
    "    print(\"There are significant differences in daily sales between the three stores.\")\n",
    "\n",
    "    # Perform post-hoc test (e.g., Tukey's HSD)\n",
    "    posthoc_result = mc.pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "\n",
    "    # Print the results of the post-hoc test\n",
    "    print(posthoc_result)\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not statistically significant.\")\n",
    "    print(\"There is not enough evidence to conclude significant differences in daily sales between the three stores.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

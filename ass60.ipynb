{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6f03b0",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "### company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "### probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5191b",
   "metadata": {},
   "source": [
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use Bayes' theorem.\n",
    "\n",
    "Let:\n",
    "- \\( A \\) be the event that an employee uses the company's health insurance plan.\n",
    "- \\( B \\) be the event that an employee is a smoker.\n",
    "\n",
    "We want to find \\( P(B|A) \\), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "Given:\n",
    "- \\( P(A) = 0.70 \\) (probability that an employee uses the health insurance plan).\n",
    "- \\( P(B|A) = 0.40 \\) (probability that an employee is a smoker given that they use the health insurance plan).\n",
    "\n",
    "We can use Bayes' theorem:\n",
    "\n",
    "\\[ P(B|A) = \\frac{P(A|B) \\times P(B)}{P(A)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the probability that an employee uses the health insurance plan given that they are a smoker.\n",
    "- \\( P(B) \\) is the probability that an employee is a smoker.\n",
    "\n",
    "However, we are not given \\( P(A|B) \\) or \\( P(B) \\). But we can find \\( P(B) \\) using the law of total probability:\n",
    "\n",
    "\\[ P(B) = P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A) \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(\\neg A) = 1 - P(A) = 1 - 0.70 = 0.30 \\) (probability that an employee does not use the health insurance plan).\n",
    "- \\( P(B|\\neg A) \\) is the probability that an employee is a smoker given that they do not use the health insurance plan.\n",
    "\n",
    "Given that \\( P(B|\\neg A) \\) is not explicitly provided, let's make the assumption that \\( P(B|\\neg A) = 0.10 \\). This is just an assumption, and actual data might be required to obtain a precise value.\n",
    "\n",
    "Now, let's calculate \\( P(B) \\):\n",
    "\n",
    "\\[ P(B) = P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A) \\]\n",
    "\\[ P(B) = (0.40 \\times 0.70) + (0.10 \\times 0.30) \\]\n",
    "\\[ P(B) = 0.28 + 0.03 \\]\n",
    "\\[ P(B) = 0.31 \\]\n",
    "\n",
    "Now, we can use Bayes' theorem to find \\( P(B|A) \\):\n",
    "\n",
    "\\[ P(B|A) = \\frac{P(A|B) \\times P(B)}{P(A)} \\]\n",
    "\\[ P(B|A) = \\frac{0.40 \\times 0.31}{0.70} \\]\n",
    "\\[ P(B|A) = \\frac{0.124}{0.70} \\]\n",
    "\\[ P(B|A) \\approx 0.1771 \\]\n",
    "\n",
    "So, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately \\(0.1771\\) or \\(17.71\\%\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f80a2",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdfbd2",
   "metadata": {},
   "source": [
    "The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of features they are designed to handle and the underlying probability distributions they assume.\n",
    "\n",
    "1. **Type of Features**:\n",
    "   - **Bernoulli Naive Bayes**: It is suitable for features that are binary or Boolean (i.e., they take on values of 0 or 1), where each feature represents the presence or absence of a particular attribute. It assumes that features are independent binary variables.\n",
    "   - **Multinomial Naive Bayes**: It is suitable for features that represent counts or frequencies of events in a multinomial distribution. It is commonly used for text classification tasks, where features typically represent word counts or term frequencies.\n",
    "\n",
    "2. **Underlying Probability Distribution**:\n",
    "   - **Bernoulli Naive Bayes**: It assumes a Bernoulli distribution for each feature, where each feature is a binary variable indicating presence or absence.\n",
    "   - **Multinomial Naive Bayes**: It assumes a multinomial distribution for each feature, where each feature represents the occurrence count of a particular term or event.\n",
    "\n",
    "3. **Handling of Feature Values**:\n",
    "   - **Bernoulli Naive Bayes**: It considers only the presence or absence of a feature, ignoring the frequency of occurrences.\n",
    "   - **Multinomial Naive Bayes**: It takes into account the frequency of occurrences of each feature value.\n",
    "\n",
    "4. **Use Cases**:\n",
    "   - **Bernoulli Naive Bayes**: It is commonly used for text classification tasks where the presence or absence of certain words in a document is important (e.g., spam detection).\n",
    "   - **Multinomial Naive Bayes**: It is also used for text classification tasks but is more suitable when the frequency of word occurrences is relevant (e.g., sentiment analysis).\n",
    "\n",
    "In summary, the choice between Bernoulli Naive Bayes and Multinomial Naive Bayes depends on the nature of the features and the underlying probability distribution assumed for the data. Bernoulli Naive Bayes is suitable for binary features, while Multinomial Naive Bayes is suitable for features representing counts or frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda94b51",
   "metadata": {},
   "source": [
    "### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ae639",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes handles missing values by considering them as a separate category or by imputing them with a specific value before performing classification. Here are two common approaches:\n",
    "\n",
    "1. **Treat Missing Values as a Separate Category**:\n",
    "   - In this approach, missing values are treated as a distinct category during the training phase. When a feature value is missing for a particular instance, it is considered as a separate category or class. During classification, the probability of belonging to this category is computed along with the probabilities of other categories.\n",
    "\n",
    "2. **Imputation with a Specific Value**:\n",
    "   - Alternatively, missing values can be imputed with a specific value before training the Bernoulli Naive Bayes classifier. Common strategies for imputation include replacing missing values with the mode (most frequent value) of the feature, or with a specific placeholder value (e.g., 0 or -1) that is not present in the original data. After imputation, the classifier is trained using the imputed dataset.\n",
    "\n",
    "Both approaches have their advantages and drawbacks. Treating missing values as a separate category preserves information about the absence of data, but it may require additional computational resources and may not be applicable in all scenarios. Imputation, on the other hand, allows for a more straightforward integration with existing algorithms but may introduce bias or inaccuracies if the imputed values do not accurately represent the missing data. The choice between these approaches depends on the specific characteristics of the dataset and the goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab4294",
   "metadata": {},
   "source": [
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7adb8",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Although it is commonly used for binary classification problems, it can be extended to handle multiple classes by employing a \"one-vs-all\" (also known as \"one-vs-rest\") approach or a \"one-vs-one\" approach.\n",
    "\n",
    "Here's how each approach works:\n",
    "\n",
    "1. **One-vs-All (OvA) Approach**:\n",
    "   - In this approach, a separate Gaussian Naive Bayes classifier is trained for each class, with the samples of that class considered as positive instances and the samples of all other classes considered as negative instances. During prediction, each classifier predicts the probability of an instance belonging to its respective class. The class with the highest predicted probability is then assigned to the instance.\n",
    "\n",
    "2. **One-vs-One (OvO) Approach**:\n",
    "   - In the one-vs-one approach, a separate Gaussian Naive Bayes classifier is trained for each pair of classes. During training, each classifier is trained to distinguish between instances of two specific classes. During prediction, each classifier votes for one of the two classes, and the class with the most votes across all classifiers is assigned to the instance.\n",
    "\n",
    "Both approaches allow Gaussian Naive Bayes to be used for multi-class classification tasks. The choice between them depends on factors such as the size of the dataset, the computational resources available, and the desired balance between accuracy and computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d23d6",
   "metadata": {},
   "source": [
    "### Q5. Assignment:\n",
    "### Data preparation:\n",
    "### Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "### datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "### is spam or not based on several input features.\n",
    "### Implementation:\n",
    "### Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "### scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "### dataset. You should use the default hyperparameters for each classifier.\n",
    "### Results:\n",
    "### Report the following performance metrics for each classifier:\n",
    "### Accuracy\n",
    "### Precision\n",
    "### Recall\n",
    "### F1 score\n",
    "### Discussion:\n",
    "### Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "### the case? Are there any limitations of Naive Bayes that you observed?\n",
    "### Conclusion:\n",
    "### Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05126487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"spambase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45345ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.44</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...   0.40  \\\n",
       "0     0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "1     0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "2     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "3     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
       "...    ...   ...     ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4595  0.31  0.00    0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4596  0.00  0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.30  0.00    0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4598  0.96  0.00    0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4599  0.00  0.00    0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "       0.41  0.42  0.778   0.43   0.44  3.756   61   278  1  \n",
       "0     0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1     0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2     0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3     0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4     0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "...     ...   ...    ...    ...    ...    ...  ...   ... ..  \n",
       "4595  0.232   0.0  0.000  0.000  0.000  1.142    3    88  0  \n",
       "4596  0.000   0.0  0.353  0.000  0.000  1.555    4    14  0  \n",
       "4597  0.718   0.0  0.000  0.000  0.000  1.404    6   118  0  \n",
       "4598  0.057   0.0  0.000  0.000  0.000  1.147    5    78  0  \n",
       "4599  0.000   0.0  0.125  0.000  0.000  1.250    5    40  0  \n",
       "\n",
       "[4600 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6f95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
